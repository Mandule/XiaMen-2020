{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettest():\n",
    "    x_test= os.path.join(base_dir,'x_test') \n",
    "    cust_avli_Q1=os.path.join(x_test,'cust_avli_Q1.csv')\n",
    "    cust_info_q1=os.path.join(x_test,'cust_info_q1.csv')\n",
    "\n",
    "    aum_test=os.path.join(x_test,'aum_test')\n",
    "    aum_m1=os.path.join(aum_test,'aum_m1.csv')\n",
    "    aum_m2=os.path.join(aum_test,'aum_m2.csv')\n",
    "    aum_m3=os.path.join(aum_test,'aum_m3.csv')\n",
    "\n",
    "\n",
    "    behavior_test=os.path.join(x_test,'behavior_test')\n",
    "    behavior_m1=os.path.join(behavior_test,'behavior_m1.csv')\n",
    "    behavior_m2=os.path.join(behavior_test,'behavior_m2.csv')\n",
    "    behavior_m3=os.path.join(behavior_test,'behavior_m3.csv')\n",
    "\n",
    "\n",
    "    big_event_test=os.path.join(x_test,'big_event_test')\n",
    "    big_event_Q1=os.path.join(big_event_test,'big_event_Q1.csv')\n",
    "\n",
    "    cunkuan_test=os.path.join(x_test,'cunkuan_test')\n",
    "    cunkuan_m1=os.path.join(cunkuan_test,'cunkuan_m1.csv')\n",
    "    cunkuan_m2=os.path.join(cunkuan_test,'cunkuan_m2.csv')\n",
    "    cunkuan_m3=os.path.join(cunkuan_test,'cunkuan_m3.csv')\n",
    "\n",
    "    data1=pd.read_csv(cust_info_q1) \n",
    "    data2=pd.read_csv(cust_avli_Q1)\n",
    "    data=pd.merge(data1,data2,on='cust_no',how='inner')\n",
    "    list_csv=[aum_m1,aum_m2,aum_m3,behavior_m1,behavior_m2,behavior_m3,big_event_Q1,cunkuan_m1,cunkuan_m2,cunkuan_m3]\n",
    "    for sir in list_csv:\n",
    "        tem=pd.read_csv(sir)\n",
    "        data=pd.merge(data,tem,on='cust_no',how='left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettrain():   \n",
    "    x_train= os.path.join(base_dir,'x_train') \n",
    "    y_train= os.path.join(base_dir,'y_train_3') \n",
    "    cust_avli_Q3=os.path.join(x_train,'cust_avli_Q3.csv')\n",
    "    cust_info_q3=os.path.join(x_train,'cust_info_q3.csv')\n",
    "    y_Q3_3=os.path.join(y_train,'y_Q3_3.csv') \n",
    "\n",
    "    cust_avli_Q4=os.path.join(x_train,'cust_avli_Q4.csv')\n",
    "    cust_info_q4=os.path.join(x_train,'cust_info_q4.csv')\n",
    "    y_Q4_3=os.path.join(y_train,'y_Q4_3.csv') \n",
    "\n",
    "\n",
    "    aum_train=os.path.join(x_train,'aum_train')\n",
    "    aum_m7=os.path.join(aum_train,'aum_m7.csv')\n",
    "    aum_m8=os.path.join(aum_train,'aum_m8.csv')\n",
    "    aum_m9=os.path.join(aum_train,'aum_m9.csv')\n",
    "    aum_m10=os.path.join(aum_train,'aum_m10.csv')\n",
    "    aum_m11=os.path.join(aum_train,'aum_m11.csv')\n",
    "    aum_m12=os.path.join(aum_train,'aum_m12.csv')\n",
    "\n",
    "\n",
    "\n",
    "    behavior_train=os.path.join(x_train,'behavior_train')\n",
    "    behavior_m7=os.path.join(behavior_train,'behavior_m7.csv')\n",
    "    behavior_m8=os.path.join(behavior_train,'behavior_m8.csv')\n",
    "    behavior_m9=os.path.join(behavior_train,'behavior_m9.csv')\n",
    "    behavior_m10=os.path.join(behavior_train,'behavior_m10.csv')\n",
    "    behavior_m11=os.path.join(behavior_train,'behavior_m11.csv')\n",
    "    behavior_m12=os.path.join(behavior_train,'behavior_m12.csv')\n",
    "\n",
    "\n",
    "    big_event_train=os.path.join(x_train,'big_event_train')\n",
    "    big_event_Q3=os.path.join(big_event_train,'big_event_Q3.csv')\n",
    "    big_event_Q4=os.path.join(big_event_train,'big_event_Q4.csv')\n",
    "\n",
    "    cunkuan_train=os.path.join(x_train,'cunkuan_train')\n",
    "    cunkuan_m7=os.path.join(cunkuan_train,'cunkuan_m7.csv')\n",
    "    cunkuan_m8=os.path.join(cunkuan_train,'cunkuan_m8.csv')\n",
    "    cunkuan_m9=os.path.join(cunkuan_train,'cunkuan_m9.csv')\n",
    "    cunkuan_m10=os.path.join(cunkuan_train,'cunkuan_m7.csv')\n",
    "    cunkuan_m11=os.path.join(cunkuan_train,'cunkuan_m8.csv')\n",
    "    cunkuan_m12=os.path.join(cunkuan_train,'cunkuan_m9.csv')\n",
    "\n",
    "    Q3List=[aum_m7,aum_m8,aum_m9,behavior_m7,behavior_m8,behavior_m9,big_event_Q3,cunkuan_m7,cunkuan_m8,cunkuan_m9]\n",
    "    Q4List=[aum_m10,aum_m11,aum_m12,behavior_m10,behavior_m11,behavior_m12,big_event_Q4,cunkuan_m10,cunkuan_m11,cunkuan_m12]\n",
    "\n",
    "    data3_1=pd.read_csv(cust_info_q3) \n",
    "    data3_2=pd.read_csv(cust_avli_Q3)\n",
    "    data3=pd.merge(data3_1,data3_2,on='cust_no',how='inner')\n",
    "    for sir in Q3List:\n",
    "        tem=pd.read_csv(sir)\n",
    "        data3=pd.merge(data3,tem,on='cust_no',how='left')\n",
    "\n",
    "    y_3=pd.read_csv(y_Q3_3)\n",
    "    data3=pd.merge(data3,y_3,on='cust_no',how='inner')\n",
    "\n",
    "\n",
    "\n",
    "    data4_1=pd.read_csv(cust_info_q4) \n",
    "    data4_2=pd.read_csv(cust_avli_Q4)\n",
    "    data4=pd.merge(data4_1,data4_2,on='cust_no',how='inner')\n",
    "    for sir in Q4List:\n",
    "        tem=pd.read_csv(sir)\n",
    "        data4=pd.merge(data4,tem,on='cust_no',how='left')\n",
    "    y_4=pd.read_csv(y_Q4_3)   \n",
    "    data4=pd.merge(data4,y_4,on='cust_no',how='inner')    \n",
    "    return data3,data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "###数据保存\n",
    "train_data3,train_data4=gettrain()\n",
    "train_data=pd.concat([train_data3,train_data4]).reset_index(drop=True)\n",
    "test_data = gettest()\n",
    "train_data.index=range(len(train_data))\n",
    "test_data['label']=2\n",
    "all_data=pd.concat([train_data,test_data]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(df,col):\n",
    "    df[col+\"_18\"]=(df.I2>18).astype(int)\n",
    "    df[col+\"_25\"]=(df.I2>25).astype(int)\n",
    "    df[col+\"_30\"]=(df.I2>30).astype(int)\n",
    "    df[col+\"_40\"]=(df.I2>40).astype(int)\n",
    "    df[col+\"_50\"]=(df.I2>50).astype(int)\n",
    "    df[col+\"_60\"]=(df.I2>60).astype(int)\n",
    "    df[col+\"_70\"]=(df.I2>70).astype(int)\n",
    "    df[col+\"_80\"]=(df.I2>80).astype(int)\n",
    "    return df\n",
    "all_data['I1']=(all_data.I1==\"男\").astype(int)##男女转化为0-1\n",
    "all_data=get_age(all_data,'I2')##年纪卡阈值\n",
    "all_data.drop('I2',axis=1) \n",
    "all_data['I12']=(all_data.I12==\"个人\").astype(int) ##转化为0-1\n",
    "\n",
    "for col in [\"I3\",\"I5\",\"I8\",\"I10\",\"I13\",\"I14\"]:\n",
    "    all_data=pd.merge(all_data.drop(col,axis=1),pd.get_dummies(all_data[col],col),left_index=True,right_index=True) \n",
    "all_data.drop([\"I7\",\"I9\",\"E11\"],axis=1) ##删掉全为空的   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=all_data[all_data[\"label\"]==2]\n",
    "test_data.drop(\"label\",axis=1)\n",
    "train_data=all_data[all_data[\"label\"]!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fea=train_data.columns.values.tolist()\n",
    "fea.remove('label')\n",
    "y_train=train_data.label\n",
    "x_train=train_data[fea]\n",
    "L=[]\n",
    "for index,value in enumerate(x_train.columns):\n",
    "    if(x_train[value]).dtype==\"object\":\n",
    "        L.append(index)\n",
    "        x_train[value].fillna(\"0\", inplace=True)\n",
    "        test_data[value].fillna(\"0\", inplace=True)\n",
    "    else:\n",
    "        x_train[value].fillna(0, inplace=True)\n",
    "        test_data[value].fillna(0, inplace=True)\n",
    "# test_pred = np.zeros(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import catboost as cat\n",
    "folds = KFold(n_splits=5, shuffle=False, random_state=2019)\n",
    "oof = np.zeros([len(x_train), 7])\n",
    "predictions = np.zeros(test_data.shape[0])  \n",
    "\n",
    "for fold_, (train_index, test_index) in enumerate(folds.split(x_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_ + 1))\n",
    "    train_x, test_x, train_y, test_y = x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[\n",
    "        train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    num_round = 1000\n",
    "    cbt_model = cat.CatBoostRegressor(iterations=10000, learning_rate=0.05, max_depth=7, verbose=100,\n",
    "                                       early_stopping_rounds=50,eval_metric='MAE',cat_features=L\n",
    "                                     )\n",
    "    cbt_model.fit(train_x, train_y, eval_set=(test_x, test_y))\n",
    "    predictions += cbt_model.predict(test_data)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##结果保存##按比例卡阈值\n",
    "predictions.tolist()\n",
    "res=[0 for i in range(len(predictions))]\n",
    "sum1=pd.read_csv(\"sum1.csv\")\n",
    "sum1=sum1[['cust_no']]\n",
    "\n",
    "tem=sorted(predictions)\n",
    "yuzhi1=tem[11738]\n",
    "yuzhi2=[76722-49011]\n",
    "for i in range(len(res)):\n",
    "    if predictions[i] <yuzhi1:\n",
    "        res[i]=-1\n",
    "    elif predictions[i]<yuzhi2:\n",
    "        res[i]=0\n",
    "    else:\n",
    "        res[i]=1\n",
    "        \n",
    "test_data['label']=res\n",
    "result['label']=result['label'].astype(\"int64\")\n",
    "test_data=test_data[['cust_no','label']]\n",
    "result=pd.merge(sum1,test_data,on='cust_no',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"cat1.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
